# -*- coding: utf-8 -*-
"""Project 5 - Neural Network SMS Text Classifier.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iG04Ud-8RaTRulSWj3e2saGAiygyfJtR

# Neural Network SMS Text Classifier

In this challenge, you need to create a machine learning model that will classify SMS messages as either "ham" or "spam". A "ham" message is a normal message sent by a friend. A "spam" message is an advertisement or a message sent by a company.

You should create a function called predict_message that takes a message string as an argument and returns a list. The first element in the list should be a number between zero and one that indicates the likeliness of "ham" (0) or "spam" (1). The second element in the list should be the word "ham" or "spam", depending on which is most likely.

For this challenge, you will use the SMS Spam Collection dataset. The dataset has already been grouped into train data and test data.
"""

# import libraries
import tensorflow as tf
import pandas as pd
from tensorflow import keras
import tensorflow_datasets as tfds
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.layers.experimental.preprocessing import TextVectorization
from tensorflow.keras import layers
from tensorflow.keras.preprocessing import sequence
tfds.disable_progress_bar()

# get data files
!wget https://cdn.freecodecamp.org/project-data/sms/train-data.tsv
!wget https://cdn.freecodecamp.org/project-data/sms/valid-data.tsv

train_file_path = "train-data.tsv"
test_file_path = "valid-data.tsv"

# Load the train dataset
train_df = pd.read_csv(train_file_path, sep="\t", header=None, names=["type", "content"])
train_df.dropna(inplace=True)
train_df.head()

# Load the test dataset
test_df = pd.read_csv(test_file_path, sep="\t", header=None, names=["type", "content"])
test_df.dropna(inplace=True)
test_df.head()

# Map "ham" to 0 and "spam" to 1 in the "type" column of train and test DataFrames
train_df["type"] = train_df["type"].map({"ham": 0, "spam": 1})
test_df["type"] = test_df["type"].map({"ham": 0, "spam": 1})

print(train_df.head())
print(test_df.head())

# Extracting labels and messages from the training DataFrame
train_labels = train_df["type"].values
train_messages = train_df["content"].values

# Creating a TensorFlow dataset from the messages and labels
train_dataset = tf.data.Dataset.from_tensor_slices((train_messages, train_labels))

train_dataset

# Extracting labels and messages from the test DataFrame
test_labels = test_df["type"].values
test_messages = test_df["content"].values

# Creating a TensorFlow dataset from the messages and labels
test_dataset = tf.data.Dataset.from_tensor_slices((test_messages, test_labels))

# Printing the element specification of the test dataset
print(test_dataset.element_spec)

# Define constants for buffer size and batch size
BUFFER_SIZE = 100
BATCH_SIZE = 32

# Shuffle, batch, and prefetch the training dataset
train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)

# Batch and prefetch the test dataset
test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)

# Define TextVectorization parameters
vec = TextVectorization(
    output_mode='int',  # Output mode is set to 'int' to represent words as integers
    max_tokens=1000,     # Maximum number of tokens to keep in the vocabulary
    output_sequence_length=1000,  # Output sequence length after padding/truncation
)

# Adapt the TextVectorization layer to the training dataset
vec.adapt(train_dataset.map(lambda text, label: text))

model = tf.keras.Sequential([
    vec,
    tf.keras.layers.Embedding(
        len(vec.get_vocabulary()),
        64,
        mask_zero=True,
    ),
    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences=True)),
    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(1)
])


model.compile(
    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),
    optimizer=tf.keras.optimizers.Adam(1e-4),
    metrics=['accuracy'],
)
model.summary()

history = model.fit(
    train_dataset,
    validation_data=test_dataset,
    validation_steps=30,
    epochs=10,
)

# Evaluate the model on the test dataset and get the loss and accuracy
test_loss, test_accuracy = model.evaluate(test_dataset)

print(f'Test Loss: {test_loss}')
print(f'Test Accuracy: {test_accuracy}')

# function to predict messages based on model
# (should return list containing prediction and label, ex. [0.008318834938108921, 'ham'])
def predict_message(input_text):
    # Predict the probability of input text being spam
    spam_probability = model.predict([input_text])
    print("Predicted spam probability:", spam_probability)

    # Extract the probability value
    probability_value = spam_probability[0][0]

    # Determine the label based on the probability
    label = "ham" if probability_value < 0.5 else "spam"

    # Return the probability and label
    return [probability_value, label]

pred_text = "how are you doing today?"
prediction = predict_message(pred_text)
print(prediction)

# Run this cell to test your function and model. Do not modify contents.
def test_predictions():
  test_messages = ["how are you doing today",
                   "sale today! to stop texts call 98912460324",
                   "i dont want to go. can we try it a different day? available sat",
                   "our new mobile video service is live. just install on your phone to start watching.",
                   "you have won Â£1000 cash! call to claim your prize.",
                   "i'll bring it tomorrow. don't forget the milk.",
                   "wow, is your arm alright. that happened to me one time too"
                  ]

  test_answers = ["ham", "spam", "ham", "spam", "spam", "ham", "ham"]
  passed = True

  for msg, ans in zip(test_messages, test_answers):
    prediction = predict_message(msg)
    if prediction[1] != ans:
      passed = False

  if passed:
    print("You passed the challenge. Great job!")
  else:
    print("You haven't passed yet. Keep trying.")

test_predictions()